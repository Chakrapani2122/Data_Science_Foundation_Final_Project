{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "17a7e5d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bjork.csv: 143\n",
      "charlesaznavour.csv: 55\n",
      "DieAntwoord.csv: 85\n",
      "duster.csv: 71\n",
      "gangstarr.csv: 88\n",
      "goonrock.csv: 2\n",
      "JPEGMAFIA.csv: 112\n",
      "justinskye.csv: 55\n",
      "kenyagrace.csv: 20\n",
      "kyan.csv: 14\n",
      "mako.csv: 32\n",
      "markmorrison.csv: 21\n",
      "maydayparade.csv: 81\n",
      "metronomy.csv: 78\n",
      "natalieimbruglia.csv: 73\n",
      "reneeelisegoldsberry.csv: 14\n",
      "roar.csv: 33\n",
      "stevieray vaughan.csv: 59\n",
      "thehollies.csv: 315\n",
      "troy.csv: 11\n",
      "vigiland.csv: 22\n",
      "WittLowry.csv: 65\n",
      "Total rows across all CSV files: 1449\n"
     ]
    }
   ],
   "source": [
    "# cell 0 - count rows in all CSV files in current folder and print per-file counts + total\n",
    "from pathlib import Path\n",
    "import csv\n",
    "\n",
    "def count_csv_rows(path):\n",
    "    try:\n",
    "        with path.open(newline='', encoding='utf-8') as f:\n",
    "            return sum(1 for _ in csv.reader(f))\n",
    "    except UnicodeDecodeError:\n",
    "        with path.open(newline='', encoding='latin-1') as f:\n",
    "            return sum(1 for _ in csv.reader(f))\n",
    "\n",
    "p = Path('.')\n",
    "csv_files = sorted(p.glob('*.csv'))\n",
    "\n",
    "if not csv_files:\n",
    "    print(\"No CSV files found in current folder.\")\n",
    "else:\n",
    "    totals = {}\n",
    "    for f in csv_files:\n",
    "        rows = count_csv_rows(f)\n",
    "        totals[f.name] = rows\n",
    "        print(f\"{f.name}: {rows}\")\n",
    "    total_sum = sum(totals.values())\n",
    "    print(\"Total rows across all CSV files:\", total_sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30550950",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Balanced dataset created: balanced_master.csv\n",
      "Final shape: (1000, 9)\n"
     ]
    }
   ],
   "source": [
    "# import pandas as pd\n",
    "\n",
    "# # File names and final target record counts\n",
    "# files_targets = {\n",
    "#     \"Billie_Ilish.csv\": 41,\n",
    "#     \"Drake.csv\": 87,\n",
    "#     \"Ed_Sheeran.csv\": 86,\n",
    "#     \"Eminem.csv\": 100,\n",
    "#     \"Justin_Bieber.csv\": 96,\n",
    "#     \"Kanye_West.csv\": 86,\n",
    "#     \"Kendrick_Lamar.csv\": 97,\n",
    "#     \"Postmalone.csv\": 63,\n",
    "#     \"Rihanna.csv\": 90,\n",
    "#     \"Taylor_Swift.csv\": 87,\n",
    "#     \"The_Weeknd.csv\": 86,\n",
    "#     \"Travis_Scott.csv\": 86\n",
    "# }\n",
    "\n",
    "# master_df = []\n",
    "\n",
    "# for file, target_count in files_targets.items():\n",
    "#     # Load CSV\n",
    "#     df = pd.read_csv(file)\n",
    "\n",
    "#     # Shuffle so selection is random\n",
    "#     df = df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "#     # Trim to the required number of rows\n",
    "#     df = df.head(target_count)\n",
    "\n",
    "#     # Add artist column (file name without .csv)\n",
    "#     artist_name = file.replace(\".csv\", \"\")\n",
    "#     df[\"artist\"] = artist_name\n",
    "\n",
    "#     master_df.append(df)\n",
    "\n",
    "# # Combine all final trimmed data\n",
    "# balanced_master = pd.concat(master_df, ignore_index=True)\n",
    "\n",
    "# # Save final dataset\n",
    "# balanced_master.to_csv(\"balanced_master.csv\", index=False)\n",
    "\n",
    "# print(\"Balanced dataset created: balanced_master.csv\")\n",
    "# print(\"Final shape:\", balanced_master.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "aa9df5b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully combined all CSV files into master_df.csv\n",
      "Final shape of the master dataframe: (1150, 9)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "master_df_list = []\n",
    "\n",
    "for f in csv_files:\n",
    "    try:\n",
    "        # Load the CSV file\n",
    "        df_temp = pd.read_csv(f)\n",
    "        \n",
    "        # Extract artist name from filename\n",
    "        artist_name = f.stem\n",
    "        \n",
    "        # Add the 'artist' column\n",
    "        df_temp['artist'] = artist_name\n",
    "        \n",
    "        # Append the dataframe to our list\n",
    "        master_df_list.append(df_temp)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Could not process file {f.name}: {e}\")\n",
    "\n",
    "# Concatenate all dataframes in the list into one\n",
    "if master_df_list:\n",
    "    master_df = pd.concat(master_df_list, ignore_index=True)\n",
    "\n",
    "    # Save the combined dataframe to a new CSV file\n",
    "    master_df.to_csv(\"master_df.csv\", index=False)\n",
    "\n",
    "    print(\"Successfully combined all CSV files into master_df.csv\")\n",
    "    print(\"Final shape of the master dataframe:\", master_df.shape)\n",
    "else:\n",
    "    print(\"No dataframes were created to combine.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43f677f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "18e8a309",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1150 entries, 0 to 1149\n",
      "Data columns (total 9 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   SongName   1150 non-null   object\n",
      " 1   AlbumName  1150 non-null   object\n",
      " 2   AlbumLink  1150 non-null   object\n",
      " 3   Year       1150 non-null   int64 \n",
      " 4   PlayCount  1150 non-null   int64 \n",
      " 5   Lyrics     1150 non-null   object\n",
      " 6   SongLink   1150 non-null   object\n",
      " 7   Duration   1150 non-null   int64 \n",
      " 8   artist     1150 non-null   object\n",
      "dtypes: int64(3), object(6)\n",
      "memory usage: 81.0+ KB\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"master_df.csv\")\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "2901ffae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "artist\n",
      "Kanye_West        136\n",
      "Taylor_Swift      126\n",
      "Travis_Scott      109\n",
      "Drake             104\n",
      "Rihanna           102\n",
      "Ed_Sheeran        100\n",
      "Eminem             95\n",
      "Kendrick_Lamar     94\n",
      "The_Weeknd         93\n",
      "Justin_Bieber      89\n",
      "Postmalone         62\n",
      "Billie_Ilish       40\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df['artist'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "b17928aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1150"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "9ebba5e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 1150 lyric files to Top Artists\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from pathlib import Path\n",
    "\n",
    "out_dir = Path(\"Top Artists\")\n",
    "out_dir.mkdir(exist_ok=True)\n",
    "\n",
    "def sanitize_filename(s: str) -> str:\n",
    "    s = s.strip()\n",
    "    s = re.sub(r'[\\\\/*?:\"<>|]', \"\", s)  # remove illegal filename chars\n",
    "    s = re.sub(r'\\s+', '_', s)  # replace whitespace with underscore\n",
    "    return s[:200]  # cap length to avoid OS limits\n",
    "\n",
    "seen = {}\n",
    "count = 0\n",
    "\n",
    "for idx, row in df.iterrows():\n",
    "    artist = str(row.get(\"artist\", \"\")).strip()\n",
    "    song = str(row.get(\"SongName\", \"\")).strip()\n",
    "    lyrics = row.get(\"Lyrics\", \"\")\n",
    "\n",
    "    a = sanitize_filename(artist) or \"unknown_artist\"\n",
    "    s = sanitize_filename(song) or f\"song_{idx}\"\n",
    "\n",
    "    base_name = f\"{a}_{s}.txt\"\n",
    "    if base_name in seen:\n",
    "        seen[base_name] += 1\n",
    "        filename = f\"{a}_{s}_{seen[base_name]}.txt\"\n",
    "    else:\n",
    "        seen[base_name] = 0\n",
    "        filename = base_name\n",
    "\n",
    "    path = out_dir / filename\n",
    "    path.write_text(str(lyrics), encoding=\"utf-8\")\n",
    "    count += 1\n",
    "\n",
    "print(f\"Saved {count} lyric files to {out_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3583c8a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# Using the 'df' DataFrame which is already loaded with 'balanced_master.csv'\n",
    "df = pd.read_csv(\"bjork.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3a4c87d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['SongName'] = df['SongName'].str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "716b6670",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking for partial duplicate song names...\n",
      "\n",
      "--- Match Found ---\n",
      "Original: Index 3, Name: Army of Me\n",
      "   Match: Index 4, Name: Army Of Me\n",
      "   Match: Index 5, Name: Army Of Me - Masseymix\n",
      "   Match: Index 6, Name: Army Of Me - Sucker Punch Remix\n",
      "\n",
      "--- Match Found ---\n",
      "Original: Index 17, Name: Blissing Me\n",
      "   Match: Index 18, Name: Blissing Me\n",
      "   Match: Index 19, Name: Blissing Me - Cornucopia Live\n",
      "   Match: Index 20, Name: Blissing Me - Harp Version\n",
      "\n",
      "--- Match Found ---\n",
      "Original: Index 21, Name: Body Memory\n",
      "   Match: Index 22, Name: Body Memory - Cornucopia Live\n",
      "\n",
      "--- Match Found ---\n",
      "Original: Index 25, Name: Cocoon\n",
      "   Match: Index 26, Name: Cocoon - Radio Edit\n",
      "\n",
      "--- Match Found ---\n",
      "Original: Index 32, Name: Courtship\n",
      "   Match: Index 33, Name: Courtship - Cornucopia Live\n",
      "\n",
      "--- Match Found ---\n",
      "Original: Index 38, Name: Declare Independence\n",
      "   Match: Index 39, Name: Declare Independence - Live\n",
      "\n",
      "--- Match Found ---\n",
      "Original: Index 46, Name: Family\n",
      "   Match: Index 47, Name: Family (Katie Gately Remix)\n",
      "\n",
      "--- Match Found ---\n",
      "Original: Index 50, Name: Future Forever\n",
      "   Match: Index 51, Name: Future Forever - Cornucopia Live\n",
      "\n",
      "--- Match Found ---\n",
      "Original: Index 52, Name: Hidden Place\n",
      "   Match: Index 53, Name: Hidden Place - Cornucopia Live\n",
      "\n",
      "--- Match Found ---\n",
      "Original: Index 64, Name: Innocence\n",
      "   Match: Index 65, Name: Innocence - Alva Noto Unitxt Remix\n",
      "   Match: Index 66, Name: Innocence - Simian Mobile Disco Remix\n",
      "\n",
      "--- Match Found ---\n",
      "Original: Index 67, Name: Isobel\n",
      "   Match: Index 68, Name: Isobel - Cornucopia Live\n",
      "   Match: Index 69, Name: Isobel - Live\n",
      "\n",
      "--- Match Found ---\n",
      "Original: Index 75, Name: Losss\n",
      "   Match: Index 76, Name: Losss - Cornucopia Live\n",
      "\n",
      "--- Match Found ---\n",
      "Original: Index 86, Name: Notget\n",
      "   Match: Index 87, Name: Notget - Cornucopia Live\n",
      "\n",
      "--- Match Found ---\n",
      "Original: Index 91, Name: Oral\n",
      "   Match: Index 92, Name: Oral - Olof Dreijer Remix\n",
      "\n",
      "--- Match Found ---\n",
      "Original: Index 95, Name: Pagan Poetry\n",
      "   Match: Index 96, Name: Pagan Poetry\n",
      "   Match: Index 97, Name: Pagan Poetry - Cornucopia Live\n",
      "   Match: Index 98, Name: Pagan Poetry - Music Box Instrumental\n",
      "   Match: Index 99, Name: Pagan Poetry - Video Edit\n",
      "\n",
      "--- Match Found ---\n",
      "Original: Index 102, Name: Possibly Maybe\n",
      "   Match: Index 103, Name: Possibly Maybe - Live\n",
      "\n",
      "--- Match Found ---\n",
      "Original: Index 111, Name: Sue Me\n",
      "   Match: Index 112, Name: Sue Me - Cornucopia Live\n",
      "\n",
      "--- Match Found ---\n",
      "Original: Index 114, Name: Sweet Intuition\n",
      "   Match: Index 115, Name: Sweet Sweet Intuition\n",
      "\n",
      "--- Match Found ---\n",
      "Original: Index 116, Name: Tabula Rasa\n",
      "   Match: Index 117, Name: Tabula Rasa - Cornucopia Live\n",
      "\n",
      "--- Match Found ---\n",
      "Original: Index 121, Name: The Gate\n",
      "   Match: Index 122, Name: the gate\n",
      "   Match: Index 123, Name: The Gate - Cornucopia Live\n",
      "   Match: Index 124, Name: the gate (edit)\n",
      "\n",
      "--- Match Found ---\n",
      "Original: Index 127, Name: Utopia\n",
      "   Match: Index 128, Name: Utopia - Cornucopia Live\n",
      "\n",
      "--- Match Found ---\n",
      "Original: Index 136, Name: Virus\n",
      "   Match: Index 137, Name: Virus (Matthew Herbert's Fever Mix)\n",
      "\n",
      "--- Match Found ---\n",
      "Original: Index 138, Name: Wanderlust\n",
      "   Match: Index 139, Name: Wanderlust - Mark Stent Mix\n",
      "   Match: Index 140, Name: Wanderlust - Matthew Herbert Remix\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Get the 'SongName' column and its corresponding indices\n",
    "songs = df['SongName'].tolist()\n",
    "indices = df.index.tolist()\n",
    "\n",
    "# A set to keep track of printed indices to avoid duplicate reports\n",
    "reported_indices = set()\n",
    "\n",
    "print(\"Checking for partial duplicate song names...\")\n",
    "\n",
    "# Iterate through each song and compare it with every other song\n",
    "for i in range(len(songs)):\n",
    "    # Skip if this song has already been reported as a duplicate\n",
    "    if i in reported_indices:\n",
    "        continue\n",
    "\n",
    "    # Clean up the first song name\n",
    "    s1 = str(songs[i]).strip().lower()\n",
    "    \n",
    "    # List to hold matches for the current song\n",
    "    matches = []\n",
    "\n",
    "    # Compare with subsequent songs\n",
    "    for j in range(i + 1, len(songs)):\n",
    "        # Clean up the second song name\n",
    "        s2 = str(songs[j]).strip().lower()\n",
    "\n",
    "        # Check for partial match (substring)\n",
    "        if s1 in s2 or s2 in s1:\n",
    "            matches.append(j)\n",
    "\n",
    "    # If any matches were found for song s1\n",
    "    if matches:\n",
    "        print(\"\\n--- Match Found ---\")\n",
    "        print(f\"Original: Index {indices[i]}, Name: {songs[i]}\")\n",
    "        reported_indices.add(i)\n",
    "        for match_idx in matches:\n",
    "            print(f\"   Match: Index {indices[match_idx]}, Name: {songs[match_idx]}\")\n",
    "            reported_indices.add(match_idx)\n",
    "\n",
    "if not reported_indices:\n",
    "    print(\"No partial duplicates found in 'SongName' column.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "f91bfed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the row at index 100\n",
    "df = df.drop(66)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "c79b21d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New shape of the DataFrame: (93, 8)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Save the updated DataFrame back to the CSV file\n",
    "df.to_csv(\"The_Weeknd.csv\", index=False)\n",
    "print(\"New shape of the DataFrame:\", df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cad8d30e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
